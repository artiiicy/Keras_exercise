{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 1000원 앞면 이미지 전체 개수: 195\n",
      "훈련용 1000원 뒷면 이미지 전체 개수: 189\n",
      "훈련용 5000원 앞면 이미지 전체 개수: 189\n",
      "훈련용 5000원 뒷면 이미지 전체 개수: 204\n",
      "훈련용 10000원 앞면 이미지 전체 개수: 192\n",
      "훈련용 10000원 뒷면 이미지 전체 개수: 189\n",
      "훈련용 50000원 앞면 이미지 전체 개수: 44\n",
      "훈련용 50000원 뒷면 이미지 전체 개수: 190 \n",
      "\n",
      "테스트용 1000원 앞면 이미지 전체 개수: 66\n",
      "테스트용 1000원 뒷면 이미지 전체 개수: 67\n",
      "테스트용 5000원 앞면 이미지 전체 개수: 66\n",
      "테스트용 5000원 뒷면 이미지 전체 개수: 66\n",
      "테스트용 10000원 앞면 이미지 전체 개수: 62\n",
      "테스트용 10000원 뒷면 이미지 전체 개수: 67\n",
      "테스트용 50000원 앞면 이미지 전체 개수: 70\n",
      "테스트용 50000원 뒷면 이미지 전체 개수: 58\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# 훈련, 테스트 데이터 directory 저장\n",
    "train_dir = './data_bill/base'\n",
    "#validation_dir = ''\n",
    "test_dir = './data_bill/test'\n",
    "\n",
    "# train directory\n",
    "train_1000b_dir = './data_bill/base/1000b'\n",
    "train_1000f_dir = './data_bill/base/1000f'\n",
    "train_5000b_dir = './data_bill/base/5000b'\n",
    "train_5000f_dir = './data_bill/base/5000f'\n",
    "train_10000b_dir = './data_bill/base/10000b'\n",
    "train_10000f_dir = './data_bill/base/10000f'\n",
    "train_50000b_dir = './data_bill/base/50000b'\n",
    "train_50000f_dir = './data_bill/base/50000f'\n",
    "\n",
    "# validation directory\n",
    "\n",
    "# test directory\n",
    "test_1000b_dir =  './data_bill/test/1000b'\n",
    "test_1000f_dir = './data_bill/test/1000f'\n",
    "test_5000b_dir = './data_bill/test/5000b'\n",
    "test_5000f_dir = './data_bill/test/5000f'\n",
    "test_10000b_dir = './data_bill/test/10000b'\n",
    "test_10000f_dir = './data_bill/test/10000f'\n",
    "test_50000b_dir = './data_bill/test/50000b'\n",
    "test_50000f_dir = './data_bill/test/50000f'\n",
    "\n",
    "print('훈련용 1000원 앞면 이미지 전체 개수:', len(os.listdir(train_1000f_dir)))\n",
    "print('훈련용 1000원 뒷면 이미지 전체 개수:', len(os.listdir(train_1000b_dir)))\n",
    "print('훈련용 5000원 앞면 이미지 전체 개수:', len(os.listdir(train_5000f_dir)))\n",
    "print('훈련용 5000원 뒷면 이미지 전체 개수:', len(os.listdir(train_5000b_dir)))\n",
    "print('훈련용 10000원 앞면 이미지 전체 개수:', len(os.listdir(train_10000f_dir)))\n",
    "print('훈련용 10000원 뒷면 이미지 전체 개수:', len(os.listdir(train_10000b_dir)))\n",
    "print('훈련용 50000원 앞면 이미지 전체 개수:', len(os.listdir(train_50000f_dir)))\n",
    "print('훈련용 50000원 뒷면 이미지 전체 개수:', len(os.listdir(train_50000b_dir)), '\\n')\n",
    "print('테스트용 1000원 앞면 이미지 전체 개수:', len(os.listdir(test_1000f_dir)))\n",
    "print('테스트용 1000원 뒷면 이미지 전체 개수:', len(os.listdir(test_1000b_dir)))\n",
    "print('테스트용 5000원 앞면 이미지 전체 개수:', len(os.listdir(test_5000f_dir)))\n",
    "print('테스트용 5000원 뒷면 이미지 전체 개수:', len(os.listdir(test_5000b_dir)))\n",
    "print('테스트용 10000원 앞면 이미지 전체 개수:', len(os.listdir(test_10000f_dir)))\n",
    "print('테스트용 10000원 뒷면 이미지 전체 개수:', len(os.listdir(test_10000b_dir)))\n",
    "print('테스트용 50000원 앞면 이미지 전체 개수:', len(os.listdir(test_50000f_dir)))\n",
    "print('테스트용 50000원 뒷면 이미지 전체 개수:', len(os.listdir(test_50000b_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1485 images belonging to 9 classes.\n",
      "Found 561 images belonging to 9 classes.\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 564s 6s/step - loss: -27.7513 - acc: 0.1275 - val_loss: -45.0043 - val_acc: 0.1101\n",
      "Epoch 2/100\n",
      " 79/100 [======================>.......] - ETA: 1:18 - loss: -40.4677 - acc: 0.1310"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3cfd136c305e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     validation_steps = 50)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf19/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1759\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf19/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 190\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf19/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf19/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2895\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf19/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image # 이미지 전처리 유틸리티 모듈\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv_base.trainable = False # conv layer 동결하여 기존 학습된 weight사용\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "'''\n",
    "fnames = sorted([os.path.join(train_1000f_dir) for fnames in os.listdir(train_1000f_dir)])\n",
    "\n",
    "img_path = './data_bill/base/1000b/1000b_001.JPG'# 증식할 이미지 선택\n",
    "img = image.load_img(img_path, target_size=(150, 150)) # 이미지 읽고 크기 변경\n",
    "\n",
    "x = image.img_to_array(img) # (150, 150, 3) 크기의 넘파이 배열로 변환\n",
    "x = x.reshape((1, ) + x.shape) # (1, 150, 150, 3) 크기로 변환\n",
    "\n",
    "# 무한으로 랜덤하게 변환된 이미지 배치 생성\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size = 1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        break\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir, # 타깃 디렉터리\n",
    "        target_size=(150, 150), # 모든 이미지의 크기를 150 × 150로 변경\n",
    "        batch_size=20, # binary_crossentropy 손실을 사용하므로 이진 레이블이 필요하다\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 100,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
